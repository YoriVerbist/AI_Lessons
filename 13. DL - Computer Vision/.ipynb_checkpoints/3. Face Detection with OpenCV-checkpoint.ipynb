{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection with OpenCV\n",
    "\n",
    "OpenCV is one of the most popular libraries for Computer Vision. Originally written in C/C++, it now provides bindings for Python. In this Notebook we will install OpenCV, explain what color models are, manipulate the pictures (for extracting some useful information from them) and draw figures on images. As a final step we will try to do face detection with photos of some famous Belgian athletes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First things first, let’s install OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you finish the installation, try importing the package to see if it works well. If you get the return without any errors, then you’re now ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we’re going to do with OpenCV is importing an image and plot it using *Matplotlib*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import the image\n",
    "img_orig = cv2.imread('resources/dog.jpg')\n",
    "plt.imshow(img_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color Models\n",
    "\n",
    "Our dog looks a little bit strange. The default setting of the color mode in OpenCV comes in the order of BGR, which is different from that of Matplotlib. Therefore to see the image in RGB mode, we need to convert it from BGR to RGB as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image from BGR into RGB\n",
    "img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A color model is a system for creating a full range of colors using primary colors. Additive models use light to represent colors in computer screens while subtractive models use inks to print those digital images on papers. The primary colors are red, green and blue (RGB) for the first one and cyan, magenta, yellow and black (CMYK) for the latter one. All the other colors we see on images are made by combining or mixing these primary colors.\n",
    "\n",
    "<img src=\"./resources/colormodels.png\" style=\"height: 250px\"/>\n",
    "\n",
    "A grayscale is another simple color model quite often used in Computer Vision. It represents images and morphologies by the intensity of black and white, which means it has only one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image into gray scale\n",
    "img_gray = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(img_gray, cmap = 'gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Drawing on images\n",
    "\n",
    "Using OpenCV you can draw figures on images. We will only demonstrate the drawing of a rectangle, but you can of course draw circles, put texts, ... as well. You will use the other methods in the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (255, 255, 255)\n",
    "line_thickness = 3\n",
    "\n",
    "x1 = 50\n",
    "y1 = 100 # upperleft corner\n",
    "\n",
    "x2 = 300\n",
    "y2 = 150 # lowerright corner\n",
    "\n",
    "cv2.rectangle(img_rgb, (x1, y1), (x2, y2), \n",
    "              color, line_thickness)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try to draw a circle arround the nose of the dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a circle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Edge detection\n",
    "\n",
    "In the previous Notebook we explained how you can use convolution filters to compute a feature map that can be used for feature detection. *Canny detection* is one of the most popular algorithms for detecting edges. It is a combination of four different filters like noise reduction, thresholding, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = cv2.imread('resources/dog.jpg')\n",
    "img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# canny detection without blurring\n",
    "img_canny = cv2.Canny(img_rgb, threshold1=127, threshold2=127)\n",
    "plt.figure(figsize = (15, 15))\n",
    "plt.subplot(1, 2, 1); plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2); plt.imshow(img_canny)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the two different threshold values, we get three ranges of values. So if the intensity gradient of a point is higher than the upper threshold, it will be considered as ‘sure-edge.’ If the gradient of a point is lower than the lower threshold, the point will be discarded. And in case of the gradient being in the middle of the two thresholds, we see its connectivity to other ‘sure-edge’ points. If there’s no connection, it will be discarded as well. We just used the median value for the two thresholds (127) without blurring and the result isn’t quite desirable.\n",
    "\n",
    "Let's play arround with the lower and upper threshold values, use blurring to reduce noise and apply two different sizes of kernels: (3x3) and (5x5). By the way, the kernel size is normally always odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the lower and upper threshold\n",
    "med_val = np.median(img_orig)\n",
    "lower = int(max(0, .7 * med_val))\n",
    "upper = int(min(255, 1.3 * med_val))\n",
    "\n",
    "# blurring with ksize = 3\n",
    "img_k3 = cv2.blur(img_orig, ksize = (3, 3))\n",
    "# canny detection with different thresholds\n",
    "edges_k3 = cv2.Canny(img_k3, threshold1 = lower, threshold2 = upper)\n",
    "edges_k3_2 = cv2.Canny(img_k3, lower, upper + 75)\n",
    "\n",
    "# blurring with ksize = 5 \n",
    "img_k5 = cv2.blur(img_orig, ksize = (5, 5))\n",
    "# canny detection with different thresholds\n",
    "edges_k5 = cv2.Canny(img_k5, lower, upper)\n",
    "edges_k5_2 = cv2.Canny(img_k5, lower, upper + 75)\n",
    "\n",
    "# plot the images\n",
    "images = [edges_k3, edges_k3_2, edges_k5, edges_k5_2]\n",
    "titles = ['blurring, kernel = 3x3, lower threshold', \n",
    "          'blurring, kernel = 3x3, higher threshold', \n",
    "          'blurring, kernel = 5x5, lower threshold', \n",
    "          'blurring, kernel = 5x5, higher threshold']\n",
    "plt.figure(figsize = (20, 15))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[i])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, blurring helps to remove noise and we got the best results with the (5x5) filter with the lower threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Face detection\n",
    "\n",
    "Face detection is a technology identifying the presence and the position of human faces in digital images. Face recognition  indicates detecting the identification of a person by his or her face. So face detection can’t tell us to whom the detected face belongs. Face recognition will be covered in the next Notebook.\n",
    "\n",
    "## Cascades\n",
    "\n",
    "Because faces are so complicated, there isn’t one simple test that will tell you if a face is found or not. Instead, there are thousands of small patterns and features that must be matched. The algorithms break the task of identifying the face into thousands of smaller, bite-sized tasks, each of which is easy to solve. These tasks are also called classifiers.\n",
    "\n",
    "For something like a face, you might have 6,000 or more classifiers, all of which must match for a face to be detected. But therein lies the problem: for face detection, the algorithm starts at the top left of a picture and moves down across small blocks of data, looking at each block, constantly asking, “Is this a face? … Is this a face? … Is this a face?” Since there are 6,000 or more tests per block, you might have millions of calculations to do, which will grind your computer to a halt.\n",
    "\n",
    "To get around this, OpenCV uses cascades. Like a series of waterfalls, the OpenCV cascade breaks the problem of detecting faces into multiple stages. For each block, it does a very rough and quick test. If that passes, it does a slightly more detailed test, and so on. The advantage is that the majority of the picture will return a negative during the first few stages, which means the algorithm won’t waste time testing all 6,000 features on it. Instead of taking hours, face detection can now be done in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Red Lions\n",
    "\n",
    "Let's try to detect all the faces of the Red Lions, the Belgian national men's field hockey team, who won the Men's Hockey World Cup in 2018 and the European Championship in 2019.\n",
    "\n",
    "We first convert the image into grayscale and use the Haar Cascade classifier to detect faces and draw a rectangle around them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "img_orig = cv2.imread('resources/redlions.jpg')\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "regions = classifier.detectMultiScale(img_gray, \n",
    "                                      1.1, #  scaleFactor is a parameter for how much the image size is reduced \n",
    "                                      3) # minNeighbors for how many neighbors each candidate rectangle should be trained\n",
    "\n",
    "for (x, y, w, h) in regions:\n",
    "    img_rgb = cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 255, 255), 2) \n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Nafi Thiam - Exercise\n",
    "\n",
    "Now use the __eye classifier__ (in the `haarcascades` folder) on a photo of Nafi Thiam (you can find the jpg in the resources), our gold medal heptathlon athlete at the 2016 Summer Olympics, the 2017 World Championships and the 2018 European Championships.\n",
    "\n",
    "Play around with the two parameters (`scaleFactor` and `minNeighbors`) and try to capture (only) the two eyes of our gold medalist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Want to try yours?\n",
    "\n",
    "Would you like to try yours with a Webcam? We can apply the same process. You can shut down the window by pressing ESC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# step 1: define detect function\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face(img):\n",
    "    \n",
    "    img_copy = img.copy()\n",
    "    face_rects = face_cascade.detectMultiScale(img_copy)\n",
    "    \n",
    "    for (x, y, w, h) in face_rects:\n",
    "        cv2.rectangle(img_copy, (x, y), (x+w, y+h), (255, 255, 255), 3)\n",
    "        \n",
    "    return img_copy\n",
    "\n",
    "# step 2: call the cam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while True: \n",
    "    \n",
    "    ret, frame = cap.read(0) \n",
    "     \n",
    "    frame = detect_face(frame)\n",
    "    cv2.imshow('Video Face Detection', frame) \n",
    " \n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    "        \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercise\n",
    "\n",
    "In the `haarcascades` directory you will find other classifiers. Try the __body classifier__ and and apply it on a photo you've taken yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
