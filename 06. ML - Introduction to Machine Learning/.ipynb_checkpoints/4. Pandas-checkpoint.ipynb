{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is the most popular Python library that is used for data analysis. Pandas is built on top of the NumPy package, meaning a lot of the structure of NumPy is used or replicated in Pandas. This Notebook can also be skipped at first. Most parts of it will be explained in the Machine Learning Notebooks. You can read it afterwords as well.\n",
    "\n",
    "<img src=\"./resources/pandas.png\"  style=\"height: 200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is an easy package to install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary two components of Pandas are the Series and DataFrame. A Series is essentially a column, and a DataFrame is a multi-dimensional table made up of a collection of Series.\n",
    "\n",
    "<img src=\"./resources/series.png\"  style=\"height: 150px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating DataFrames from scratch\n",
    "\n",
    "There are many ways to create a DataFrame from scratch, but a great option is to just use a simple dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating a dictionary\n",
    "data = {\n",
    "    'apples': [3, 2, 0, 1], \n",
    "    'oranges': [0, 3, 7, 2]\n",
    "}\n",
    "\n",
    "purchases = pd.DataFrame(data)\n",
    "\n",
    "purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Index of this DataFrame was given to us on creation as the numbers 0-3, but we could also create our own when we initialize the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases = pd.DataFrame(data, index=['June', 'Robert', 'Lily', 'David'])\n",
    "\n",
    "purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we could locate a customer's order by using his name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases.loc['June']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading data from CSVs\n",
    "\n",
    "It’s quite simple to load data from various file formats into a DataFrame. With CSV files all you need is a single line to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"resources/IMDB-Movie-Data.csv\", index_col=\"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do when opening a new dataset is print out a few rows to keep as a visual reference. We accomplish this with `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also pass a number as well: `movies_df.head(10)` would output the top ten rows. To see the last five rows use `.tail()`. `tail()`also accepts a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the index in our DataFrame is the Title column, which you can see by how the word Title is slightly lower than the rest of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.loc['Sing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.info()` provides the essential details about your dataset, such as the number of rows and columns, the number of non-null values, what type of data is in each column, and how much memory your DataFrame is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another fast and useful attribute is .shape, which outputs just a tuple of (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning and transforming data\n",
    "\n",
    "### Handling duplicates\n",
    "\n",
    "This dataset does not have duplicate rows, but it is always important to verify you aren't aggregating duplicate rows.\n",
    "\n",
    "To demonstrate, let's simply just double up our movies DataFrame by appending it to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = movies_df.append(movies_df)\n",
    "\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try dropping duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop_duplicates()\n",
    "\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little verbose to keep assigning DataFrames to the same variable like in this example. For this reason, Pandas has the inplace keyword argument on many of its methods. Using `inplace=True` will modify the DataFrame object in place. Now our temp_df will have the transformed data automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column cleanup\n",
    "\n",
    "Many times datasets will have verbose column names with symbols, upper and lowercase words, spaces, and typos. To make selecting data by column name easier we can spend a little time cleaning up their names.\n",
    "\n",
    "Here's how to print the column names of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.rename()` method to rename certain or all columns via a dict. We don't want parentheses, so let's rename those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.rename(columns={\n",
    "        'Runtime (Minutes)': 'Runtime', \n",
    "        'Revenue (Millions)': 'Revenue_millions'\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to lowercase, to remove special characters, and to replace spaces with underscores if you'll be working with a dataset for some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns = [col.lower() for col in movies_df]\n",
    "\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Let's first calculate to total number of nulls in each column of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that our data has 128 missing values for revenue_millions and 64 missing values for metascore.\n",
    "\n",
    "There are two options in dealing with nulls:\n",
    "\n",
    "1. Get rid of rows or columns with nulls\n",
    "2. Replace nulls with non-null values, a technique known as imputation\n",
    "\n",
    "Removing nulls is pretty simple:\n",
    "\n",
    "```python\n",
    "movies_df.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "This operation will delete any row with at least a single null value. This obviously seems like a waste since there's perfectly good data in the other columns of those dropped rows.\n",
    "\n",
    "So instead we can impute that null with another value, usually the mean. Let's look at imputing the missing values in the revenue_millions column. First we'll extract that column into its own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues = movies_df['revenue_millions']\n",
    "\n",
    "revenues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_revenue = revenues.mean()\n",
    "mean_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues.fillna(mean_revenue, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DataFrame slicing, selecting, extracting\n",
    "\n",
    "Let's have a look at some methods of slicing, selecting, and extracting you'll need to use constantly.\n",
    "\n",
    "It's important to note that, although many methods are the same, DataFrames and Series have different attributes, so you need to know which type you are working with or else you will receive attribute errors.\n",
    "\n",
    "### By column\n",
    "\n",
    "Extract a column using square brackets. This will return a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = movies_df['genre']\n",
    "\n",
    "type(genre_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a column as a DataFrame, you need to pass a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = movies_df[['genre']]\n",
    "\n",
    "type(genre_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's just a list, adding another column name is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = movies_df[['genre', 'rating']]\n",
    "\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By rows\n",
    "\n",
    "For rows, we have two options:\n",
    "\n",
    "1. .loc locates by name\n",
    "2. .iloc locates by numerical index\n",
    "\n",
    "Remember that we are still indexed by movie Title, so to use .loc we give it the Title of a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = movies_df.loc[\"Prometheus\"]\n",
    "\n",
    "movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, with iloc we give it the numerical index of Prometheus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = movies_df.iloc[1]\n",
    "\n",
    "movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use loc and iloc as well to select multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset1 = movies_df.loc['Prometheus':'Sing']\n",
    "movie_subset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset2 = movies_df.iloc[1:4] # the movie at index 4 (Suicide Squad) is not included\n",
    "movie_subset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selections\n",
    "\n",
    "We’ve gone over how to select columns and rows, but what if we want to make a conditional selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset3 = movies_df[movies_df['director'] == \"Ridley Scott\"]\n",
    "movie_subset3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at conditional selections using numerical values by filtering the DataFrame by ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['rating'] >= 8.6].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make some richer conditionals by using logical operators: | for \"or\" and & for \"and\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[(movies_df['director'] == 'Christopher Nolan') | (movies_df['director'] == 'Ridley Scott')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculating statistics\n",
    "\n",
    "A very useful command is `.describe()` which outputs summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to get statistics on the entire data frame or a series (a column etc).\n",
    "\n",
    "- `.mean()` returns the mean of all columns\n",
    "- `.corr()` returns the correlation between columns in a data frame\n",
    "- `.count()` returns the number of non-null values in each data frame column\n",
    "- `.max()` returns the highest value in each column\n",
    "- `.min()` returns the lowest value in each column \n",
    "- `.median()` returns the median of each column \n",
    "- `.std()` returns the standard deviation of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['rating' , 'revenue_millions', 'metascore']].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
